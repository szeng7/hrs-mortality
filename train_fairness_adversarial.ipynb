{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3IQI1FOj5MSx",
    "outputId": "deef3fc8-b31b-4298-d6fe-1db6605b946b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fairlearn in /usr/local/lib/python3.10/dist-packages (0.12.0)\n",
      "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from fairlearn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from fairlearn) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from fairlearn) (1.5.2)\n",
      "Requirement already satisfied: scipy>=1.9.3 in /usr/local/lib/python3.10/dist-packages (from fairlearn) (1.13.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.3->fairlearn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.3->fairlearn) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.3->fairlearn) (2024.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.1->fairlearn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.1->fairlearn) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.3->fairlearn) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "pip install fairlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "aEADuAtU5nNZ"
   },
   "outputs": [],
   "source": [
    "#defining all load data scenarios\n",
    "import pandas as pd\n",
    "from train_eval_functions import *\n",
    "import importlib\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "\n",
    "def stratify_wrapper(train_df, id_test_df, ood_test_df, n_samples=200):\n",
    "    train_class_distribution = train_df['mortality_ten_years'].value_counts(normalize=True)\n",
    "    rounded_distribution = (train_class_distribution * 100).round().astype(int)\n",
    "    #print(rounded_distribution)\n",
    "    #print(id_test_df['mortality_ten_years'].value_counts(normalize=True))\n",
    "    #print(ood_test_df['mortality_ten_years'].value_counts(normalize=True))\n",
    "\n",
    "    id_test_df = stratified_sample(id_test_df, target_col='mortality_ten_years', n_samples=n_samples, class_distribution=rounded_distribution)\n",
    "    ood_test_df = stratified_sample(ood_test_df, target_col='mortality_ten_years', n_samples=n_samples, class_distribution=rounded_distribution)\n",
    "\n",
    "    return train_df, id_test_df, ood_test_df\n",
    "\n",
    "def fill_na_val(train_df, id_test_df, ood_test_df):\n",
    "    train_df = train_df.fillna(-999)\n",
    "    id_test_df = id_test_df.fillna(-999)\n",
    "    ood_test_df = ood_test_df.fillna(-999)\n",
    "\n",
    "    X_train, y_train = split_dataset_into_x_y(train_df, 'mortality_ten_years')\n",
    "    X_id_test, y_id_test = split_dataset_into_x_y(id_test_df, 'mortality_ten_years')\n",
    "    X_ood_test, y_ood_test = split_dataset_into_x_y(ood_test_df, 'mortality_ten_years')\n",
    "\n",
    "    return X_train, y_train, X_id_test, y_id_test, X_ood_test, y_ood_test\n",
    "\n",
    "def impute(train_df, id_test_df, ood_test_df):\n",
    "    imp_norm_pipe = Pipeline(steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"mean\",missing_values=pd.NA)),\n",
    "            (\"normalizer\", StandardScaler())])\n",
    "\n",
    "    X_train, y_train = split_dataset_into_x_y(train_df, 'mortality_ten_years')\n",
    "    X_id_test, y_id_test = split_dataset_into_x_y(id_test_df, 'mortality_ten_years')\n",
    "    X_ood_test, y_ood_test = split_dataset_into_x_y(ood_test_df, 'mortality_ten_years')\n",
    "\n",
    "    all_na_cols = X_train.columns[X_train.isna().all()]\n",
    "    X_train = X_train.drop(columns=all_na_cols).fillna(np.nan)\n",
    "    X_train = pd.DataFrame(imp_norm_pipe.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "\n",
    "    X_id_test = X_id_test.drop(columns=all_na_cols).fillna(np.nan)\n",
    "    X_id_test = pd.DataFrame(imp_norm_pipe.transform(X_id_test), columns=X_id_test.columns, index=X_id_test.index)\n",
    "\n",
    "    X_ood_test = X_ood_test.drop(columns=all_na_cols).fillna(np.nan)\n",
    "    X_ood_test = pd.DataFrame(imp_norm_pipe.transform(X_ood_test), columns=X_ood_test.columns, index=X_ood_test.index)\n",
    "\n",
    "    return X_train, y_train, X_id_test, y_id_test, X_ood_test, y_ood_test\n",
    "\n",
    "def load_data_scenario_1(imputed=False):\n",
    "    '''\n",
    "    Train: 2006-2010\n",
    "    ID Test: 2012\n",
    "    OOD Test: 2014-2016\n",
    "    '''\n",
    "\n",
    "    data_dict = pd.read_pickle('cleaned_data_stacked_and_dict.pkl')\n",
    "    train_df = pd.concat([data_dict['2006'], data_dict['2008'], data_dict['2010']], ignore_index=True)\n",
    "    id_test_df = data_dict['2012']\n",
    "    ood_test_df = pd.concat([data_dict['2014'], data_dict['2016']], ignore_index=True)\n",
    "\n",
    "    train_df, id_test_df, ood_test_df = stratify_wrapper(train_df, id_test_df, ood_test_df, n_samples=200)\n",
    "\n",
    "    if not imputed:\n",
    "        return fill_na_val(train_df, id_test_df, ood_test_df)\n",
    "    else:\n",
    "        return impute(train_df, id_test_df, ood_test_df)\n",
    "\n",
    "def load_data_scenario_2(imputed=False):\n",
    "    '''\n",
    "    Train: 2006-2008\n",
    "    ID Test: 2010-2012\n",
    "    OOD Test: 2014-2016\n",
    "    '''\n",
    "    data_dict = pd.read_pickle('cleaned_data_stacked_and_dict.pkl')\n",
    "    train_df = pd.concat([data_dict['2006'], data_dict['2008']], ignore_index=True)\n",
    "    id_test_df = pd.concat([data_dict['2010'], data_dict['2012']], ignore_index=True)\n",
    "    ood_test_df = pd.concat([data_dict['2014'], data_dict['2016']], ignore_index=True)\n",
    "\n",
    "    train_df, id_test_df, ood_test_df = stratify_wrapper(train_df, id_test_df, ood_test_df, n_samples=200)\n",
    "\n",
    "    if not imputed:\n",
    "        return fill_na_val(train_df, id_test_df, ood_test_df)\n",
    "    else:\n",
    "        return impute(train_df, id_test_df, ood_test_df)\n",
    "\n",
    "def load_data_scenario_3(imputed=False):\n",
    "    '''\n",
    "    Train: 2006-2010 (80%)\n",
    "    ID Test: 2006-2010 (20%)\n",
    "    OOD Test: 2016\n",
    "    '''\n",
    "    data_dict = pd.read_pickle('cleaned_data_stacked_and_dict.pkl')\n",
    "\n",
    "    dataset = pd.concat([data_dict['2006'], data_dict['2008'], data_dict['2010']], ignore_index=True)\n",
    "    X_dataset = dataset.drop(columns=[\"mortality_ten_years\"])\n",
    "    y_dataset = dataset[\"mortality_ten_years\"]\n",
    "    X_train, X_id_test, y_train, y_id_test = train_test_split(X_dataset, y_dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "    train_df = pd.concat([X_train, y_train], axis=1)\n",
    "    id_test_df = pd.concat([X_id_test, y_id_test], axis=1)\n",
    "    ood_test_df = data_dict['2016']\n",
    "\n",
    "    train_df, id_test_df, ood_test_df = stratify_wrapper(train_df, id_test_df, ood_test_df, n_samples=200)\n",
    "\n",
    "    if not imputed:\n",
    "        return fill_na_val(train_df, id_test_df, ood_test_df)\n",
    "    else:\n",
    "        return impute(train_df, id_test_df, ood_test_df)\n",
    "\n",
    "def load_data_scenario_4(imputed=False):\n",
    "    '''\n",
    "    Train: 2006-2014 (80%) all regions except 11 1 2\n",
    "    ID Test: 2006-2014 (20%) all regions except 11 1 2\n",
    "    OOD Test: 2016. 11, 1, 2\n",
    "    '''\n",
    "    data_dict = pd.read_pickle('cleaned_data_stacked_and_dict.pkl')\n",
    "    dataset = pd.concat([data_dict['2006'], data_dict['2008'], data_dict['2010'], data_dict['2012'], data_dict['2014']], ignore_index=True)\n",
    "\n",
    "    dataset.drop(dataset[dataset['state_live_current'].isin([97, 98, 99, 11, 1, 2])].index, inplace=True)\n",
    "\n",
    "    X_dataset = dataset.drop(columns=[\"mortality_ten_years\"])\n",
    "    y_dataset = dataset[\"mortality_ten_years\"]\n",
    "\n",
    "    X_train, X_id_test, y_train, y_id_test = train_test_split(X_dataset, y_dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "    train_df = pd.concat([X_train, y_train], axis=1)\n",
    "    id_test_df = pd.concat([X_id_test, y_id_test], axis=1)\n",
    "    ood_test_df = data_dict['2016']\n",
    "    ood_test_df.drop(ood_test_df[~ood_test_df['state_live_current'].isin([11, 1, 2])].index, inplace=True)\n",
    "\n",
    "    train_df, id_test_df, ood_test_df = stratify_wrapper(train_df, id_test_df, ood_test_df, n_samples=200)\n",
    "\n",
    "    if not imputed:\n",
    "        return fill_na_val(train_df, id_test_df, ood_test_df)\n",
    "    else:\n",
    "        return impute(train_df, id_test_df, ood_test_df)\n",
    "\n",
    "def load_data_scenario_5(imputed=False):\n",
    "    '''\n",
    "    Train: 2006-2016 (80%) regions 3, 4, 5, 6\n",
    "    ID Test: 2006-2016 (20%) regions 3, 4, 5, 6\n",
    "    OOD Test: 2006-2016 region 1\n",
    "    '''\n",
    "    data_dict = pd.read_pickle('cleaned_data_stacked_and_dict.pkl')\n",
    "\n",
    "    dataset = pd.concat([data_dict['2006'], data_dict['2008'], data_dict['2010'], data_dict['2012'], data_dict['2014'], data_dict['2016']], ignore_index=True)\n",
    "    dataset.drop(dataset[dataset['race'].isin([-999, 8, 9, 2, 7])].index, inplace=True)\n",
    "\n",
    "    X_dataset = dataset.drop(columns=[\"mortality_ten_years\"])\n",
    "    y_dataset = dataset[\"mortality_ten_years\"]\n",
    "\n",
    "    X_train, X_id_test, y_train, y_id_test = train_test_split(X_dataset, y_dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "    train_df = pd.concat([X_train, y_train], axis=1)\n",
    "    id_test_df = pd.concat([X_id_test, y_id_test], axis=1)\n",
    "    ood_test_df = pd.concat([data_dict['2006'], data_dict['2008'], data_dict['2010'], data_dict['2012'], data_dict['2014'], data_dict['2016']], ignore_index=True)\n",
    "    ood_test_df.drop(ood_test_df[~ood_test_df['state_live_current'].isin([1])].index, inplace=True)\n",
    "\n",
    "    train_df, id_test_df, ood_test_df = stratify_wrapper(train_df, id_test_df, ood_test_df, n_samples=200)\n",
    "\n",
    "    if not imputed:\n",
    "        return fill_na_val(train_df, id_test_df, ood_test_df)\n",
    "    else:\n",
    "        return impute(train_df, id_test_df, ood_test_df)\n",
    "\n",
    "def load_data_scenario_6(imputed=False):\n",
    "    '''\n",
    "    Train: 2006-2010 (80%)\n",
    "    ID Test: 2010-2012 (20%)\n",
    "    OOD Test: 2014-2016\n",
    "    '''\n",
    "    data_dict = pd.read_pickle('cleaned_data_stacked_and_dict.pkl')\n",
    "\n",
    "    dataset = data_dict['2010']\n",
    "    X_dataset = dataset.drop(columns=[\"mortality_ten_years\"])\n",
    "    y_dataset = dataset[\"mortality_ten_years\"]\n",
    "\n",
    "    X_train, X_id_test, y_train, y_id_test = train_test_split(X_dataset, y_dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "    dataset = pd.concat([data_dict['2006'], data_dict['2008']], ignore_index=True)\n",
    "    X_train = pd.concat([dataset.drop(columns=[\"mortality_ten_years\"]), X_train])\n",
    "    y_train = pd.concat([dataset[\"mortality_ten_years\"], y_train])\n",
    "\n",
    "    id_test_df = data_dict['2012']\n",
    "    X_id_test = pd.concat([id_test_df, X_id_test])\n",
    "    y_id_test = pd.concat([id_test_df[\"mortality_ten_years\"], y_id_test])\n",
    "\n",
    "    train_df = pd.concat([X_train, y_train], axis=1)\n",
    "    id_test_df = pd.concat([X_id_test.drop(columns=[\"mortality_ten_years\"]), y_id_test], axis=1)\n",
    "    ood_test_df = pd.concat([data_dict['2014'], data_dict['2016']], ignore_index=True)\n",
    "\n",
    "    train_df, id_test_df, ood_test_df = stratify_wrapper(train_df, id_test_df, ood_test_df, n_samples=200)\n",
    "\n",
    "    if not imputed:\n",
    "        return fill_na_val(train_df, id_test_df, ood_test_df)\n",
    "    else:\n",
    "        return impute(train_df, id_test_df, ood_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "tBtqd8ewTwso"
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from fairlearn.metrics import *\n",
    "\n",
    "def get_fairness_metrics_adv(model, X_train, y_train, X_id_test, y_id_test, X_ood_test, y_ood_test, sensitive_attr=\"\", mute=False):\n",
    "\n",
    "    protected_attributes = ['race', 'gender', 'state_live_current', 'income_current', 'age', 'education_current']\n",
    "\n",
    "    if sensitive_attr != \"\":\n",
    "        protected_attributes = [sensitive_attr]\n",
    "\n",
    "    all_sp = {}\n",
    "    all_eo = {}\n",
    "\n",
    "    for attribute in protected_attributes:\n",
    "        if not mute: print(f\"{attribute}:\\n\")\n",
    "        attr_sp = []\n",
    "        attr_eo = []\n",
    "\n",
    "        for dataset_name, (X, y, sensitive_attr) in {\n",
    "            \"Train\": (imp_norm_drop_miss_pipe.fit_transform(X_train), y_train, X_train[attribute]),\n",
    "            \"ID Test\": (imp_norm_drop_miss_pipe.fit_transform(X_id_test), y_id_test, X_id_test[attribute]),\n",
    "            \"OOD Test\": (imp_norm_drop_miss_pipe.fit_transform(X_ood_test), y_ood_test, X_ood_test[attribute]),\n",
    "        }.items():\n",
    "            y_pred = model.predict(X)\n",
    "            sp = demographic_parity_difference(y_pred, y, sensitive_features=sensitive_attr)\n",
    "            if not mute: print(f\"Statistical Parity Difference ({dataset_name}): {sp}\")\n",
    "            attr_sp.append(sp)\n",
    "\n",
    "            eo = equalized_odds_difference(y_pred, y, sensitive_features=sensitive_attr)\n",
    "            if not mute: print(f\"Equalized Odds Difference ({dataset_name}): {eo}\")\n",
    "            attr_eo.append(eo)\n",
    "\n",
    "        all_sp[attribute] = attr_sp\n",
    "        all_eo[attribute] = attr_eo\n",
    "\n",
    "    return all_sp, all_eo\n",
    "\n",
    "\n",
    "imp_norm_drop_miss_pipe = make_column_transformer(\n",
    "    (\n",
    "        Pipeline(\n",
    "            [\n",
    "                (\"imputer\", SimpleImputer(strategy=\"mean\",missing_values=pd.NA)),\n",
    "                (\"normalizer\", StandardScaler())\n",
    "            ]\n",
    "        ),\n",
    "        make_column_selector(dtype_include=\"float64\"),\n",
    "    ),\n",
    "    (\n",
    "        Pipeline(\n",
    "            [\n",
    "                (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                (\"encoder\", OrdinalEncoder(handle_unknown=\"use_encoded_value\",unknown_value=-1)),\n",
    "            ]\n",
    "        ),\n",
    "        make_column_selector(dtype_include=\"category\"),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qx2BcZJ0Fmyy"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def train_adv(X_train_imp_drop_normed, X_train_imp_dropped, y_train_dropped, X_id_test_imp_dropped, y_id_test_dropped, X_ood_test_imp_dropped, y_ood_test_dropped):\n",
    "\n",
    "  best_sp, best_eo = float('inf'), float('inf')\n",
    "  no_improvement_count = 0\n",
    "  patience = 2\n",
    "\n",
    "  adv_clf = AdversarialFairnessClassifier(\n",
    "      backend=\"torch\",\n",
    "      predictor_model=[200, \"relu\", 100, \"relu\", 50, \"sigmoid\"],\n",
    "      adversary_model = [50, \"relu\", 25, \"relu\", 10, \"leaky_relu\"],\n",
    "      batch_size=32,\n",
    "      learning_rate=0.001,\n",
    "      alpha=1,\n",
    "      random_state=42,\n",
    "      shuffle=True,\n",
    "      epochs=100,\n",
    "      constraints=\"demographic_parity\"\n",
    "  )\n",
    "\n",
    "  EVAL_EVERY = 5\n",
    "\n",
    "  metrics_history = defaultdict(list)\n",
    "\n",
    "  for epoch in range(adv_clf.epochs):\n",
    "      adv_clf.partial_fit(X_train_imp_drop_normed, y_train_dropped, sensitive_features=X_train_imp_dropped[ADV_SENS_ATTR])\n",
    "\n",
    "      y_train_pred = adv_clf.predict(X_train_imp_drop_normed)\n",
    "      acc = accuracy_score(y_train_dropped, y_train_pred)\n",
    "      metrics_history[\"epoch\"].append(epoch + 1)\n",
    "      metrics_history[\"accuracy\"].append(acc)\n",
    "\n",
    "      if epoch % EVAL_EVERY == 0:\n",
    "        sp, eo = get_fairness_metrics_adv(\n",
    "            adv_clf, X_train_imp_dropped, y_train_dropped, X_id_test_imp_dropped, y_id_test_dropped, X_ood_test_imp_dropped, y_ood_test_dropped,\n",
    "            sensitive_attr=ADV_SENS_ATTR, mute=True\n",
    "        )\n",
    "        metrics_history[\"sp\"].append(sp[ADV_SENS_ATTR][0])\n",
    "        metrics_history[\"eo\"].append(eo[ADV_SENS_ATTR][0])\n",
    "        #print((sp, eo))\n",
    "        if eo[ADV_SENS_ATTR][0] < best_eo:\n",
    "            best_sp, best_eo = sp[ADV_SENS_ATTR][0], eo[ADV_SENS_ATTR][0]\n",
    "            no_improvement_count = 0\n",
    "            print(\"Fairness metrics improved, continuing...\")\n",
    "        else:\n",
    "            no_improvement_count += 1\n",
    "            print(f\"No improvement in fairness metrics for {no_improvement_count} evaluations.\")\n",
    "\n",
    "        #stop early\n",
    "        if no_improvement_count >= patience:\n",
    "            print(\"Early stopping: No significant improvement in fairness metrics.\")\n",
    "            break\n",
    "\n",
    "      # Optionally, print progress\n",
    "      print(f\"Epoch {epoch + 1}/{adv_clf.epochs} - Accuracy: {acc:.4f}\")\n",
    "  return adv_clf, metrics_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "ijz-FYzInuUS"
   },
   "outputs": [],
   "source": [
    "all_was_dist = []\n",
    "all_sp = []\n",
    "all_eo = []\n",
    "all_max_gap = []\n",
    "\n",
    "ADV_SENS_ATTR = \"state_live_current\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rENHAchaRHId",
    "outputId": "a5a5e322-496e-4f4e-a83a-77741c471766"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-8b35e4531d17>:67: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  train_df = pd.concat([data_dict['2006'], data_dict['2008'], data_dict['2010']], ignore_index=True)\n",
      "<ipython-input-2-8b35e4531d17>:48: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_train = X_train.drop(columns=all_na_cols).fillna(np.nan)\n",
      "<ipython-input-2-8b35e4531d17>:51: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_id_test = X_id_test.drop(columns=all_na_cols).fillna(np.nan)\n",
      "<ipython-input-2-8b35e4531d17>:54: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_ood_test = X_ood_test.drop(columns=all_na_cols).fillna(np.nan)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 - Accuracy: 0.6314\n",
      "Epoch 2/100 - Accuracy: 0.6390\n",
      "Epoch 3/100 - Accuracy: 0.6503\n",
      "Epoch 4/100 - Accuracy: 0.6623\n",
      "Epoch 5/100 - Accuracy: 0.6727\n",
      "Epoch 6/100 - Accuracy: 0.6811\n",
      "Epoch 7/100 - Accuracy: 0.6900\n",
      "Epoch 8/100 - Accuracy: 0.6957\n",
      "Epoch 9/100 - Accuracy: 0.7020\n",
      "Epoch 10/100 - Accuracy: 0.7071\n",
      "Epoch 11/100 - Accuracy: 0.7103\n",
      "Epoch 12/100 - Accuracy: 0.7125\n",
      "Epoch 13/100 - Accuracy: 0.7147\n",
      "Epoch 14/100 - Accuracy: 0.7169\n",
      "Epoch 15/100 - Accuracy: 0.7181\n",
      "Epoch 16/100 - Accuracy: 0.7195\n",
      "Epoch 17/100 - Accuracy: 0.7221\n",
      "Epoch 18/100 - Accuracy: 0.7237\n",
      "Epoch 19/100 - Accuracy: 0.7251\n",
      "Epoch 20/100 - Accuracy: 0.7263\n",
      "Epoch 21/100 - Accuracy: 0.7281\n",
      "Epoch 22/100 - Accuracy: 0.7290\n",
      "Epoch 23/100 - Accuracy: 0.7297\n",
      "Epoch 24/100 - Accuracy: 0.7310\n",
      "Epoch 25/100 - Accuracy: 0.7324\n",
      "Epoch 26/100 - Accuracy: 0.7338\n",
      "Epoch 27/100 - Accuracy: 0.7350\n",
      "Epoch 28/100 - Accuracy: 0.7361\n",
      "Epoch 29/100 - Accuracy: 0.7372\n",
      "Epoch 30/100 - Accuracy: 0.7383\n",
      "Epoch 31/100 - Accuracy: 0.7394\n",
      "Epoch 32/100 - Accuracy: 0.7402\n",
      "Epoch 33/100 - Accuracy: 0.7412\n",
      "Epoch 34/100 - Accuracy: 0.7422\n",
      "Epoch 35/100 - Accuracy: 0.7437\n",
      "Epoch 36/100 - Accuracy: 0.7448\n",
      "Epoch 37/100 - Accuracy: 0.7457\n",
      "Epoch 38/100 - Accuracy: 0.7467\n",
      "Epoch 39/100 - Accuracy: 0.7481\n",
      "Epoch 40/100 - Accuracy: 0.7485\n",
      "Epoch 41/100 - Accuracy: 0.7493\n",
      "Epoch 42/100 - Accuracy: 0.7503\n",
      "Epoch 43/100 - Accuracy: 0.7512\n",
      "Epoch 44/100 - Accuracy: 0.7520\n",
      "Epoch 45/100 - Accuracy: 0.7524\n",
      "Fairness metrics improved, continuing...\n",
      "Epoch 46/100 - Accuracy: 0.7525\n",
      "Epoch 47/100 - Accuracy: 0.7536\n",
      "Epoch 48/100 - Accuracy: 0.7544\n",
      "Epoch 49/100 - Accuracy: 0.7552\n",
      "Epoch 50/100 - Accuracy: 0.7559\n",
      "Fairness metrics improved, continuing...\n",
      "Epoch 51/100 - Accuracy: 0.7562\n",
      "Epoch 52/100 - Accuracy: 0.7567\n",
      "Epoch 53/100 - Accuracy: 0.7574\n",
      "Epoch 54/100 - Accuracy: 0.7581\n",
      "Epoch 55/100 - Accuracy: 0.7585\n",
      "No improvement in fairness metrics for 1 evaluations.\n",
      "Epoch 56/100 - Accuracy: 0.7590\n",
      "Epoch 57/100 - Accuracy: 0.7594\n",
      "Epoch 58/100 - Accuracy: 0.7599\n",
      "Epoch 59/100 - Accuracy: 0.7604\n",
      "Epoch 60/100 - Accuracy: 0.7608\n",
      "No improvement in fairness metrics for 2 evaluations.\n",
      "Early stopping: No significant improvement in fairness metrics.\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_id_test, y_id_test, X_ood_test, y_ood_test = load_data_scenario_1(imputed=True)\n",
    "X_train_imp = X_train\n",
    "X_id_test_imp = X_id_test\n",
    "X_ood_test_imp = X_ood_test\n",
    "\n",
    "X_train_imp_dropped = X_train_imp[X_train_imp[ADV_SENS_ATTR].notna()]\n",
    "y_train_dropped = y_train[X_train_imp[ADV_SENS_ATTR].notna()]\n",
    "X_train_imp_drop_normed = imp_norm_drop_miss_pipe.fit_transform(X_train_imp_dropped)\n",
    "\n",
    "X_id_test_imp_dropped = X_id_test_imp[X_id_test_imp[ADV_SENS_ATTR].notna()]\n",
    "y_id_test_dropped = y_id_test[X_id_test_imp[ADV_SENS_ATTR].notna()]\n",
    "X_id_test_imp_drop_normed = imp_norm_drop_miss_pipe.transform(X_id_test_imp_dropped)\n",
    "\n",
    "X_ood_test_imp_dropped = X_ood_test_imp[X_ood_test_imp[ADV_SENS_ATTR].notna()]\n",
    "y_ood_test_dropped = y_ood_test[X_ood_test_imp[ADV_SENS_ATTR].notna()]\n",
    "X_ood_test_imp_drop_normed = imp_norm_drop_miss_pipe.transform(X_ood_test_imp_dropped)\n",
    "\n",
    "adv_clf, metrics_history = train_adv(X_train_imp_drop_normed, X_train_imp_dropped, y_train_dropped, X_id_test_imp_dropped, y_id_test_dropped, X_ood_test_imp_dropped, y_ood_test_dropped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NriAAAoSjJ8g",
    "outputId": "9704a163-fc29-49bc-9fcd-fa98adb39a50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state_live_current:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:486: UserWarning: X has feature names, but AdversarialFairnessClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:486: UserWarning: X has feature names, but AdversarialFairnessClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical Parity Difference (Train): 0.13039912520503005\n",
      "Equalized Odds Difference (Train): 0.4691575637206223\n",
      "Statistical Parity Difference (ID Test): 0.38333333333333336\n",
      "Equalized Odds Difference (ID Test): 0.5\n",
      "Statistical Parity Difference (OOD Test): 0.75\n",
      "Equalized Odds Difference (OOD Test): 0.75\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f'./{ADV_SENS_ATTR}/metrics_1_eval.pkl', 'wb') as file:\n",
    "    pickle.dump(metrics_history, file)\n",
    "\n",
    "evaluate(adv_clf, X_id_test, y_id_test, X_ood_test, y_ood_test, save_as=f\"./{ADV_SENS_ATTR}/adv_1_eval.txt\")\n",
    "\n",
    "sp, eo = get_fairness_metrics_adv(\n",
    "      adv_clf, X_train_imp_dropped, y_train_dropped, X_id_test_imp_dropped, y_id_test_dropped, X_ood_test_imp_dropped, y_ood_test_dropped,\n",
    "      sensitive_attr=ADV_SENS_ATTR, mute=False\n",
    "  )\n",
    "\n",
    "\n",
    "all_sp.append(sp)\n",
    "all_eo.append(eo)\n",
    "\n",
    "wd = calculate_wasserstein_distance(X_train, X_id_test, X_ood_test, mute=True)\n",
    "all_was_dist.append(wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OW2vNic5oSjb",
    "outputId": "5ec1fdc4-e1f8-484a-ad75-341d074cf7c0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-8b35e4531d17>:85: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  train_df = pd.concat([data_dict['2006'], data_dict['2008']], ignore_index=True)\n",
      "<ipython-input-2-8b35e4531d17>:48: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_train = X_train.drop(columns=all_na_cols).fillna(np.nan)\n",
      "<ipython-input-2-8b35e4531d17>:51: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_id_test = X_id_test.drop(columns=all_na_cols).fillna(np.nan)\n",
      "<ipython-input-2-8b35e4531d17>:54: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_ood_test = X_ood_test.drop(columns=all_na_cols).fillna(np.nan)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 - Accuracy: 0.5839\n",
      "Epoch 2/100 - Accuracy: 0.6070\n",
      "Epoch 3/100 - Accuracy: 0.6390\n",
      "Epoch 4/100 - Accuracy: 0.6576\n",
      "Epoch 5/100 - Accuracy: 0.6690\n",
      "Epoch 6/100 - Accuracy: 0.6752\n",
      "Epoch 7/100 - Accuracy: 0.6808\n",
      "Epoch 8/100 - Accuracy: 0.6833\n",
      "Epoch 9/100 - Accuracy: 0.6871\n",
      "Epoch 10/100 - Accuracy: 0.6897\n",
      "Epoch 11/100 - Accuracy: 0.6929\n",
      "Epoch 12/100 - Accuracy: 0.6956\n",
      "Epoch 13/100 - Accuracy: 0.6986\n",
      "Epoch 14/100 - Accuracy: 0.7014\n",
      "Epoch 15/100 - Accuracy: 0.7035\n",
      "Epoch 16/100 - Accuracy: 0.7052\n",
      "Epoch 17/100 - Accuracy: 0.7054\n",
      "Epoch 18/100 - Accuracy: 0.7076\n",
      "Epoch 19/100 - Accuracy: 0.7101\n",
      "Epoch 20/100 - Accuracy: 0.7124\n",
      "Epoch 21/100 - Accuracy: 0.7132\n",
      "Epoch 22/100 - Accuracy: 0.7147\n",
      "Epoch 23/100 - Accuracy: 0.7163\n",
      "Epoch 24/100 - Accuracy: 0.7181\n",
      "Epoch 25/100 - Accuracy: 0.7198\n",
      "Epoch 26/100 - Accuracy: 0.7209\n",
      "Epoch 27/100 - Accuracy: 0.7223\n",
      "Epoch 28/100 - Accuracy: 0.7247\n",
      "Epoch 29/100 - Accuracy: 0.7252\n",
      "Epoch 30/100 - Accuracy: 0.7266\n",
      "Epoch 31/100 - Accuracy: 0.7274\n",
      "Epoch 32/100 - Accuracy: 0.7288\n",
      "Epoch 33/100 - Accuracy: 0.7299\n",
      "Epoch 34/100 - Accuracy: 0.7307\n",
      "Epoch 35/100 - Accuracy: 0.7307\n",
      "Epoch 36/100 - Accuracy: 0.7318\n",
      "Epoch 37/100 - Accuracy: 0.7322\n",
      "Epoch 38/100 - Accuracy: 0.7329\n",
      "Epoch 39/100 - Accuracy: 0.7330\n",
      "Epoch 40/100 - Accuracy: 0.7332\n",
      "Epoch 41/100 - Accuracy: 0.7336\n",
      "Epoch 42/100 - Accuracy: 0.7341\n",
      "Epoch 43/100 - Accuracy: 0.7341\n",
      "Epoch 44/100 - Accuracy: 0.7341\n",
      "Epoch 45/100 - Accuracy: 0.7337\n",
      "Epoch 46/100 - Accuracy: 0.7340\n",
      "Epoch 47/100 - Accuracy: 0.7343\n",
      "Epoch 48/100 - Accuracy: 0.7351\n",
      "Epoch 49/100 - Accuracy: 0.7363\n",
      "Epoch 50/100 - Accuracy: 0.7366\n",
      "Epoch 51/100 - Accuracy: 0.7380\n",
      "Epoch 52/100 - Accuracy: 0.7396\n",
      "Epoch 53/100 - Accuracy: 0.7402\n",
      "Epoch 54/100 - Accuracy: 0.7414\n",
      "Epoch 55/100 - Accuracy: 0.7424\n",
      "Epoch 56/100 - Accuracy: 0.7436\n",
      "Epoch 57/100 - Accuracy: 0.7448\n",
      "Epoch 58/100 - Accuracy: 0.7463\n",
      "Epoch 59/100 - Accuracy: 0.7475\n",
      "Epoch 60/100 - Accuracy: 0.7485\n",
      "Epoch 61/100 - Accuracy: 0.7495\n",
      "Epoch 62/100 - Accuracy: 0.7507\n",
      "Epoch 63/100 - Accuracy: 0.7518\n",
      "Epoch 64/100 - Accuracy: 0.7528\n",
      "Epoch 65/100 - Accuracy: 0.7537\n",
      "Fairness metrics improved, continuing...\n",
      "Epoch 66/100 - Accuracy: 0.7547\n",
      "Epoch 67/100 - Accuracy: 0.7551\n",
      "Epoch 68/100 - Accuracy: 0.7564\n",
      "Epoch 69/100 - Accuracy: 0.7566\n",
      "Epoch 70/100 - Accuracy: 0.7574\n",
      "Fairness metrics improved, continuing...\n",
      "Epoch 71/100 - Accuracy: 0.7583\n",
      "Epoch 72/100 - Accuracy: 0.7590\n",
      "Epoch 73/100 - Accuracy: 0.7596\n",
      "Epoch 74/100 - Accuracy: 0.7606\n",
      "Epoch 75/100 - Accuracy: 0.7609\n",
      "No improvement in fairness metrics for 1 evaluations.\n",
      "Epoch 76/100 - Accuracy: 0.7619\n",
      "Epoch 77/100 - Accuracy: 0.7619\n",
      "Epoch 78/100 - Accuracy: 0.7631\n",
      "Epoch 79/100 - Accuracy: 0.7643\n",
      "Epoch 80/100 - Accuracy: 0.7655\n",
      "No improvement in fairness metrics for 2 evaluations.\n",
      "Early stopping: No significant improvement in fairness metrics.\n",
      "state_live_current:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:486: UserWarning: X has feature names, but AdversarialFairnessClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:486: UserWarning: X has feature names, but AdversarialFairnessClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical Parity Difference (Train): 0.15481777987075845\n",
      "Equalized Odds Difference (Train): 0.18710691823899372\n",
      "Statistical Parity Difference (ID Test): 0.36458333333333337\n",
      "Equalized Odds Difference (ID Test): 0.8\n",
      "Statistical Parity Difference (OOD Test): 0.7777777777777778\n",
      "Equalized Odds Difference (OOD Test): 0.8\n"
     ]
    }
   ],
   "source": [
    "load_num = 2\n",
    "\n",
    "X_train, y_train, X_id_test, y_id_test, X_ood_test, y_ood_test = load_data_scenario_2(imputed=True)\n",
    "X_train_imp = X_train\n",
    "X_id_test_imp = X_id_test\n",
    "X_ood_test_imp = X_ood_test\n",
    "\n",
    "X_train_imp_dropped = X_train_imp[X_train_imp[ADV_SENS_ATTR].notna()]\n",
    "y_train_dropped = y_train[X_train_imp[ADV_SENS_ATTR].notna()]\n",
    "X_train_imp_drop_normed = imp_norm_drop_miss_pipe.fit_transform(X_train_imp_dropped)\n",
    "\n",
    "X_id_test_imp_dropped = X_id_test_imp[X_id_test_imp[ADV_SENS_ATTR].notna()]\n",
    "y_id_test_dropped = y_id_test[X_id_test_imp[ADV_SENS_ATTR].notna()]\n",
    "X_id_test_imp_drop_normed = imp_norm_drop_miss_pipe.transform(X_id_test_imp_dropped)\n",
    "\n",
    "X_ood_test_imp_dropped = X_ood_test_imp[X_ood_test_imp[ADV_SENS_ATTR].notna()]\n",
    "y_ood_test_dropped = y_ood_test[X_ood_test_imp[ADV_SENS_ATTR].notna()]\n",
    "X_ood_test_imp_drop_normed = imp_norm_drop_miss_pipe.transform(X_ood_test_imp_dropped)\n",
    "\n",
    "adv_clf, metrics_history = train_adv(X_train_imp_drop_normed, X_train_imp_dropped, y_train_dropped, X_id_test_imp_dropped, y_id_test_dropped, X_ood_test_imp_dropped, y_ood_test_dropped)\n",
    "\n",
    "with open(f'./{ADV_SENS_ATTR}/metrics_{load_num}_eval.pkl', 'wb') as file:\n",
    "    pickle.dump(metrics_history, file)\n",
    "\n",
    "evaluate(adv_clf, X_id_test, y_id_test, X_ood_test, y_ood_test, save_as=f\"./{ADV_SENS_ATTR}/adv_{load_num}_eval.txt\")\n",
    "\n",
    "sp, eo = get_fairness_metrics_adv(\n",
    "      adv_clf, X_train_imp_dropped, y_train_dropped, X_id_test_imp_dropped, y_id_test_dropped, X_ood_test_imp_dropped, y_ood_test_dropped,\n",
    "      sensitive_attr=ADV_SENS_ATTR, mute=False\n",
    "  )\n",
    "\n",
    "\n",
    "all_sp.append(sp)\n",
    "all_eo.append(eo)\n",
    "\n",
    "wd = calculate_wasserstein_distance(X_train, X_id_test, X_ood_test, mute=True)\n",
    "all_was_dist.append(wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JKtKv3G1onVO",
    "outputId": "b03c43d6-c16b-4af3-9b8c-530c8012f174"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-8b35e4531d17>:104: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataset = pd.concat([data_dict['2006'], data_dict['2008'], data_dict['2010']], ignore_index=True)\n",
      "<ipython-input-2-8b35e4531d17>:48: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_train = X_train.drop(columns=all_na_cols).fillna(np.nan)\n",
      "<ipython-input-2-8b35e4531d17>:51: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_id_test = X_id_test.drop(columns=all_na_cols).fillna(np.nan)\n",
      "<ipython-input-2-8b35e4531d17>:54: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_ood_test = X_ood_test.drop(columns=all_na_cols).fillna(np.nan)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 - Accuracy: 0.6303\n",
      "Epoch 2/100 - Accuracy: 0.6381\n",
      "Epoch 3/100 - Accuracy: 0.6500\n",
      "Epoch 4/100 - Accuracy: 0.6621\n",
      "Epoch 5/100 - Accuracy: 0.6722\n",
      "Epoch 6/100 - Accuracy: 0.6815\n",
      "Epoch 7/100 - Accuracy: 0.6899\n",
      "Epoch 8/100 - Accuracy: 0.6959\n",
      "Epoch 9/100 - Accuracy: 0.7018\n",
      "Epoch 10/100 - Accuracy: 0.7067\n",
      "Epoch 11/100 - Accuracy: 0.7100\n",
      "Epoch 12/100 - Accuracy: 0.7121\n",
      "Epoch 13/100 - Accuracy: 0.7149\n",
      "Epoch 14/100 - Accuracy: 0.7171\n",
      "Epoch 15/100 - Accuracy: 0.7181\n",
      "Epoch 16/100 - Accuracy: 0.7199\n",
      "Epoch 17/100 - Accuracy: 0.7218\n",
      "Epoch 18/100 - Accuracy: 0.7234\n",
      "Epoch 19/100 - Accuracy: 0.7250\n",
      "Epoch 20/100 - Accuracy: 0.7270\n",
      "Epoch 21/100 - Accuracy: 0.7285\n",
      "Epoch 22/100 - Accuracy: 0.7297\n",
      "Epoch 23/100 - Accuracy: 0.7305\n",
      "Epoch 24/100 - Accuracy: 0.7316\n",
      "Epoch 25/100 - Accuracy: 0.7334\n",
      "Epoch 26/100 - Accuracy: 0.7344\n",
      "Epoch 27/100 - Accuracy: 0.7353\n",
      "Epoch 28/100 - Accuracy: 0.7362\n",
      "Epoch 29/100 - Accuracy: 0.7373\n",
      "Epoch 30/100 - Accuracy: 0.7379\n",
      "Epoch 31/100 - Accuracy: 0.7387\n",
      "Epoch 32/100 - Accuracy: 0.7393\n",
      "Epoch 33/100 - Accuracy: 0.7406\n",
      "Epoch 34/100 - Accuracy: 0.7418\n",
      "Epoch 35/100 - Accuracy: 0.7431\n",
      "Epoch 36/100 - Accuracy: 0.7438\n",
      "Epoch 37/100 - Accuracy: 0.7452\n",
      "Epoch 38/100 - Accuracy: 0.7461\n",
      "Epoch 39/100 - Accuracy: 0.7470\n",
      "Epoch 40/100 - Accuracy: 0.7483\n",
      "Epoch 41/100 - Accuracy: 0.7495\n",
      "Epoch 42/100 - Accuracy: 0.7508\n",
      "Epoch 43/100 - Accuracy: 0.7510\n",
      "Epoch 44/100 - Accuracy: 0.7512\n",
      "Epoch 45/100 - Accuracy: 0.7509\n",
      "Fairness metrics improved, continuing...\n",
      "Epoch 46/100 - Accuracy: 0.7514\n",
      "Epoch 47/100 - Accuracy: 0.7519\n",
      "Epoch 48/100 - Accuracy: 0.7526\n",
      "Epoch 49/100 - Accuracy: 0.7527\n",
      "Epoch 50/100 - Accuracy: 0.7524\n",
      "No improvement in fairness metrics for 1 evaluations.\n",
      "Epoch 51/100 - Accuracy: 0.7524\n",
      "Epoch 52/100 - Accuracy: 0.7530\n",
      "Epoch 53/100 - Accuracy: 0.7533\n",
      "Epoch 54/100 - Accuracy: 0.7535\n",
      "Epoch 55/100 - Accuracy: 0.7534\n",
      "No improvement in fairness metrics for 2 evaluations.\n",
      "Early stopping: No significant improvement in fairness metrics.\n",
      "state_live_current:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:486: UserWarning: X has feature names, but AdversarialFairnessClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:486: UserWarning: X has feature names, but AdversarialFairnessClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical Parity Difference (Train): 0.17210884353741496\n",
      "Equalized Odds Difference (Train): 0.5396205041064854\n",
      "Statistical Parity Difference (ID Test): 0.4246031746031746\n",
      "Equalized Odds Difference (ID Test): 0.6666666666666667\n",
      "Statistical Parity Difference (OOD Test): 0.7\n",
      "Equalized Odds Difference (OOD Test): 0.8\n"
     ]
    }
   ],
   "source": [
    "load_num = 3\n",
    "\n",
    "X_train, y_train, X_id_test, y_id_test, X_ood_test, y_ood_test = load_data_scenario_3(imputed=True)\n",
    "X_train_imp = X_train\n",
    "X_id_test_imp = X_id_test\n",
    "X_ood_test_imp = X_ood_test\n",
    "\n",
    "X_train_imp_dropped = X_train_imp[X_train_imp[ADV_SENS_ATTR].notna()]\n",
    "y_train_dropped = y_train[X_train_imp[ADV_SENS_ATTR].notna()]\n",
    "X_train_imp_drop_normed = imp_norm_drop_miss_pipe.fit_transform(X_train_imp_dropped)\n",
    "\n",
    "X_id_test_imp_dropped = X_id_test_imp[X_id_test_imp[ADV_SENS_ATTR].notna()]\n",
    "y_id_test_dropped = y_id_test[X_id_test_imp[ADV_SENS_ATTR].notna()]\n",
    "X_id_test_imp_drop_normed = imp_norm_drop_miss_pipe.transform(X_id_test_imp_dropped)\n",
    "\n",
    "X_ood_test_imp_dropped = X_ood_test_imp[X_ood_test_imp[ADV_SENS_ATTR].notna()]\n",
    "y_ood_test_dropped = y_ood_test[X_ood_test_imp[ADV_SENS_ATTR].notna()]\n",
    "X_ood_test_imp_drop_normed = imp_norm_drop_miss_pipe.transform(X_ood_test_imp_dropped)\n",
    "\n",
    "adv_clf, metrics_history = train_adv(X_train_imp_drop_normed, X_train_imp_dropped, y_train_dropped, X_id_test_imp_dropped, y_id_test_dropped, X_ood_test_imp_dropped, y_ood_test_dropped)\n",
    "\n",
    "with open(f'./{ADV_SENS_ATTR}/metrics_{load_num}_eval.pkl', 'wb') as file:\n",
    "    pickle.dump(metrics_history, file)\n",
    "\n",
    "evaluate(adv_clf, X_id_test, y_id_test, X_ood_test, y_ood_test, save_as=f\"./{ADV_SENS_ATTR}/adv_{load_num}_eval.txt\")\n",
    "\n",
    "sp, eo = get_fairness_metrics_adv(\n",
    "      adv_clf, X_train_imp_dropped, y_train_dropped, X_id_test_imp_dropped, y_id_test_dropped, X_ood_test_imp_dropped, y_ood_test_dropped,\n",
    "      sensitive_attr=ADV_SENS_ATTR, mute=False\n",
    "  )\n",
    "\n",
    "\n",
    "all_sp.append(sp)\n",
    "all_eo.append(eo)\n",
    "\n",
    "wd = calculate_wasserstein_distance(X_train, X_id_test, X_ood_test, mute=True)\n",
    "all_was_dist.append(wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VdtqV5k7orCd",
    "outputId": "e5566c4e-2ecb-4393-8c4f-f03008363475"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-8b35e4531d17>:127: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataset = pd.concat([data_dict['2006'], data_dict['2008'], data_dict['2010'], data_dict['2012'], data_dict['2014']], ignore_index=True)\n",
      "<ipython-input-2-8b35e4531d17>:48: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_train = X_train.drop(columns=all_na_cols).fillna(np.nan)\n",
      "<ipython-input-2-8b35e4531d17>:51: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_id_test = X_id_test.drop(columns=all_na_cols).fillna(np.nan)\n",
      "<ipython-input-2-8b35e4531d17>:54: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_ood_test = X_ood_test.drop(columns=all_na_cols).fillna(np.nan)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 - Accuracy: 0.7039\n",
      "Epoch 2/100 - Accuracy: 0.7039\n",
      "Epoch 3/100 - Accuracy: 0.7040\n",
      "Epoch 4/100 - Accuracy: 0.7044\n",
      "Epoch 5/100 - Accuracy: 0.7054\n",
      "Epoch 6/100 - Accuracy: 0.7090\n",
      "Epoch 7/100 - Accuracy: 0.7157\n",
      "Epoch 8/100 - Accuracy: 0.7236\n",
      "Epoch 9/100 - Accuracy: 0.7301\n",
      "Epoch 10/100 - Accuracy: 0.7347\n",
      "Epoch 11/100 - Accuracy: 0.7378\n",
      "Epoch 12/100 - Accuracy: 0.7400\n",
      "Epoch 13/100 - Accuracy: 0.7422\n",
      "Epoch 14/100 - Accuracy: 0.7447\n",
      "Epoch 15/100 - Accuracy: 0.7467\n",
      "Epoch 16/100 - Accuracy: 0.7487\n",
      "Epoch 17/100 - Accuracy: 0.7507\n",
      "Epoch 18/100 - Accuracy: 0.7521\n",
      "Epoch 19/100 - Accuracy: 0.7527\n",
      "Epoch 20/100 - Accuracy: 0.7535\n",
      "Fairness metrics improved, continuing...\n",
      "Epoch 21/100 - Accuracy: 0.7543\n",
      "Epoch 22/100 - Accuracy: 0.7548\n",
      "Epoch 23/100 - Accuracy: 0.7555\n",
      "Epoch 24/100 - Accuracy: 0.7566\n",
      "Epoch 25/100 - Accuracy: 0.7574\n",
      "Fairness metrics improved, continuing...\n",
      "Epoch 26/100 - Accuracy: 0.7589\n",
      "Epoch 27/100 - Accuracy: 0.7598\n",
      "Epoch 28/100 - Accuracy: 0.7616\n",
      "Epoch 29/100 - Accuracy: 0.7627\n",
      "Epoch 30/100 - Accuracy: 0.7640\n",
      "Fairness metrics improved, continuing...\n",
      "Epoch 31/100 - Accuracy: 0.7646\n",
      "Epoch 32/100 - Accuracy: 0.7653\n",
      "Epoch 33/100 - Accuracy: 0.7659\n",
      "Epoch 34/100 - Accuracy: 0.7666\n",
      "Epoch 35/100 - Accuracy: 0.7674\n",
      "Fairness metrics improved, continuing...\n",
      "Epoch 36/100 - Accuracy: 0.7682\n",
      "Epoch 37/100 - Accuracy: 0.7698\n",
      "Epoch 38/100 - Accuracy: 0.7708\n",
      "Epoch 39/100 - Accuracy: 0.7713\n",
      "Epoch 40/100 - Accuracy: 0.7722\n",
      "Fairness metrics improved, continuing...\n",
      "Epoch 41/100 - Accuracy: 0.7729\n",
      "Epoch 42/100 - Accuracy: 0.7732\n",
      "Epoch 43/100 - Accuracy: 0.7739\n",
      "Epoch 44/100 - Accuracy: 0.7746\n",
      "Epoch 45/100 - Accuracy: 0.7750\n",
      "Fairness metrics improved, continuing...\n",
      "Epoch 46/100 - Accuracy: 0.7754\n",
      "Epoch 47/100 - Accuracy: 0.7763\n",
      "Epoch 48/100 - Accuracy: 0.7771\n",
      "Epoch 49/100 - Accuracy: 0.7776\n",
      "Epoch 50/100 - Accuracy: 0.7786\n",
      "Fairness metrics improved, continuing...\n",
      "Epoch 51/100 - Accuracy: 0.7791\n",
      "Epoch 52/100 - Accuracy: 0.7798\n",
      "Epoch 53/100 - Accuracy: 0.7804\n",
      "Epoch 54/100 - Accuracy: 0.7808\n",
      "Epoch 55/100 - Accuracy: 0.7814\n",
      "No improvement in fairness metrics for 1 evaluations.\n",
      "Epoch 56/100 - Accuracy: 0.7825\n",
      "Epoch 57/100 - Accuracy: 0.7835\n",
      "Epoch 58/100 - Accuracy: 0.7841\n",
      "Epoch 59/100 - Accuracy: 0.7844\n",
      "Epoch 60/100 - Accuracy: 0.7847\n",
      "No improvement in fairness metrics for 2 evaluations.\n",
      "Early stopping: No significant improvement in fairness metrics.\n",
      "state_live_current:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:486: UserWarning: X has feature names, but AdversarialFairnessClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:486: UserWarning: X has feature names, but AdversarialFairnessClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical Parity Difference (Train): 0.052602436323366586\n",
      "Equalized Odds Difference (Train): 0.09139784946236562\n",
      "Statistical Parity Difference (ID Test): 0.23203026481715008\n",
      "Equalized Odds Difference (ID Test): 0.5\n",
      "Statistical Parity Difference (OOD Test): 0.21875\n",
      "Equalized Odds Difference (OOD Test): 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "load_num = 4\n",
    "\n",
    "X_train, y_train, X_id_test, y_id_test, X_ood_test, y_ood_test = load_data_scenario_4(imputed=True)\n",
    "X_train_imp = X_train\n",
    "X_id_test_imp = X_id_test\n",
    "X_ood_test_imp = X_ood_test\n",
    "\n",
    "X_train_imp_dropped = X_train_imp[X_train_imp[ADV_SENS_ATTR].notna()]\n",
    "y_train_dropped = y_train[X_train_imp[ADV_SENS_ATTR].notna()]\n",
    "X_train_imp_drop_normed = imp_norm_drop_miss_pipe.fit_transform(X_train_imp_dropped)\n",
    "\n",
    "X_id_test_imp_dropped = X_id_test_imp[X_id_test_imp[ADV_SENS_ATTR].notna()]\n",
    "y_id_test_dropped = y_id_test[X_id_test_imp[ADV_SENS_ATTR].notna()]\n",
    "X_id_test_imp_drop_normed = imp_norm_drop_miss_pipe.transform(X_id_test_imp_dropped)\n",
    "\n",
    "X_ood_test_imp_dropped = X_ood_test_imp[X_ood_test_imp[ADV_SENS_ATTR].notna()]\n",
    "y_ood_test_dropped = y_ood_test[X_ood_test_imp[ADV_SENS_ATTR].notna()]\n",
    "X_ood_test_imp_drop_normed = imp_norm_drop_miss_pipe.transform(X_ood_test_imp_dropped)\n",
    "\n",
    "adv_clf, metrics_history = train_adv(X_train_imp_drop_normed, X_train_imp_dropped, y_train_dropped, X_id_test_imp_dropped, y_id_test_dropped, X_ood_test_imp_dropped, y_ood_test_dropped)\n",
    "\n",
    "with open(f'./{ADV_SENS_ATTR}/metrics_{load_num}_eval.pkl', 'wb') as file:\n",
    "    pickle.dump(metrics_history, file)\n",
    "\n",
    "evaluate(adv_clf, X_id_test, y_id_test, X_ood_test, y_ood_test, save_as=f\"./{ADV_SENS_ATTR}/adv_{load_num}_eval.txt\")\n",
    "\n",
    "sp, eo = get_fairness_metrics_adv(\n",
    "      adv_clf, X_train_imp_dropped, y_train_dropped, X_id_test_imp_dropped, y_id_test_dropped, X_ood_test_imp_dropped, y_ood_test_dropped,\n",
    "      sensitive_attr=ADV_SENS_ATTR, mute=False\n",
    "  )\n",
    "\n",
    "\n",
    "all_sp.append(sp)\n",
    "all_eo.append(eo)\n",
    "\n",
    "wd = calculate_wasserstein_distance(X_train, X_id_test, X_ood_test, mute=True)\n",
    "all_was_dist.append(wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aBgog6Ybos4N",
    "outputId": "0363f0bb-a213-4836-e817-77b78c0aecdd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-8b35e4531d17>:156: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataset = pd.concat([data_dict['2006'], data_dict['2008'], data_dict['2010'], data_dict['2012'], data_dict['2014'], data_dict['2016']], ignore_index=True)\n",
      "<ipython-input-2-8b35e4531d17>:166: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  ood_test_df = pd.concat([data_dict['2006'], data_dict['2008'], data_dict['2010'], data_dict['2012'], data_dict['2014'], data_dict['2016']], ignore_index=True)\n",
      "<ipython-input-2-8b35e4531d17>:48: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_train = X_train.drop(columns=all_na_cols).fillna(np.nan)\n",
      "<ipython-input-2-8b35e4531d17>:51: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_id_test = X_id_test.drop(columns=all_na_cols).fillna(np.nan)\n",
      "<ipython-input-2-8b35e4531d17>:54: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_ood_test = X_ood_test.drop(columns=all_na_cols).fillna(np.nan)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 - Accuracy: 0.7320\n",
      "Epoch 2/100 - Accuracy: 0.7320\n",
      "Epoch 3/100 - Accuracy: 0.7320\n",
      "Epoch 4/100 - Accuracy: 0.7320\n",
      "Epoch 5/100 - Accuracy: 0.7320\n",
      "Epoch 6/100 - Accuracy: 0.7322\n",
      "Epoch 7/100 - Accuracy: 0.7333\n",
      "Epoch 8/100 - Accuracy: 0.7355\n",
      "Epoch 9/100 - Accuracy: 0.7402\n",
      "Epoch 10/100 - Accuracy: 0.7460\n",
      "Fairness metrics improved, continuing...\n",
      "Epoch 11/100 - Accuracy: 0.7503\n",
      "Epoch 12/100 - Accuracy: 0.7533\n",
      "Epoch 13/100 - Accuracy: 0.7552\n",
      "Epoch 14/100 - Accuracy: 0.7572\n",
      "Epoch 15/100 - Accuracy: 0.7587\n",
      "Fairness metrics improved, continuing...\n",
      "Epoch 16/100 - Accuracy: 0.7603\n",
      "Epoch 17/100 - Accuracy: 0.7621\n",
      "Epoch 18/100 - Accuracy: 0.7634\n",
      "Epoch 19/100 - Accuracy: 0.7646\n",
      "Epoch 20/100 - Accuracy: 0.7656\n",
      "Fairness metrics improved, continuing...\n",
      "Epoch 21/100 - Accuracy: 0.7662\n",
      "Epoch 22/100 - Accuracy: 0.7661\n",
      "Epoch 23/100 - Accuracy: 0.7669\n",
      "Epoch 24/100 - Accuracy: 0.7670\n",
      "Epoch 25/100 - Accuracy: 0.7674\n",
      "No improvement in fairness metrics for 1 evaluations.\n",
      "Epoch 26/100 - Accuracy: 0.7678\n",
      "Epoch 27/100 - Accuracy: 0.7686\n",
      "Epoch 28/100 - Accuracy: 0.7690\n",
      "Epoch 29/100 - Accuracy: 0.7689\n",
      "Epoch 30/100 - Accuracy: 0.7690\n",
      "No improvement in fairness metrics for 2 evaluations.\n",
      "Early stopping: No significant improvement in fairness metrics.\n",
      "state_live_current:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:486: UserWarning: X has feature names, but AdversarialFairnessClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:486: UserWarning: X has feature names, but AdversarialFairnessClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical Parity Difference (Train): 0.3564356435643564\n",
      "Equalized Odds Difference (Train): 0.7884057971014493\n",
      "Statistical Parity Difference (ID Test): 0.5454545454545454\n",
      "Equalized Odds Difference (ID Test): 1.0\n",
      "Statistical Parity Difference (OOD Test): 0.0\n",
      "Equalized Odds Difference (OOD Test): 0.0\n"
     ]
    }
   ],
   "source": [
    "load_num = 5\n",
    "\n",
    "X_train, y_train, X_id_test, y_id_test, X_ood_test, y_ood_test = load_data_scenario_5(imputed=True)\n",
    "X_train_imp = X_train\n",
    "X_id_test_imp = X_id_test\n",
    "X_ood_test_imp = X_ood_test\n",
    "\n",
    "X_train_imp_dropped = X_train_imp[X_train_imp[ADV_SENS_ATTR].notna()]\n",
    "y_train_dropped = y_train[X_train_imp[ADV_SENS_ATTR].notna()]\n",
    "X_train_imp_drop_normed = imp_norm_drop_miss_pipe.fit_transform(X_train_imp_dropped)\n",
    "\n",
    "X_id_test_imp_dropped = X_id_test_imp[X_id_test_imp[ADV_SENS_ATTR].notna()]\n",
    "y_id_test_dropped = y_id_test[X_id_test_imp[ADV_SENS_ATTR].notna()]\n",
    "X_id_test_imp_drop_normed = imp_norm_drop_miss_pipe.transform(X_id_test_imp_dropped)\n",
    "\n",
    "X_ood_test_imp_dropped = X_ood_test_imp[X_ood_test_imp[ADV_SENS_ATTR].notna()]\n",
    "y_ood_test_dropped = y_ood_test[X_ood_test_imp[ADV_SENS_ATTR].notna()]\n",
    "X_ood_test_imp_drop_normed = imp_norm_drop_miss_pipe.transform(X_ood_test_imp_dropped)\n",
    "\n",
    "adv_clf, metrics_history = train_adv(X_train_imp_drop_normed, X_train_imp_dropped, y_train_dropped, X_id_test_imp_dropped, y_id_test_dropped, X_ood_test_imp_dropped, y_ood_test_dropped)\n",
    "\n",
    "\n",
    "with open(f'./{ADV_SENS_ATTR}/metrics_{load_num}_eval.pkl', 'wb') as file:\n",
    "    pickle.dump(metrics_history, file)\n",
    "\n",
    "evaluate(adv_clf, X_id_test, y_id_test, X_ood_test, y_ood_test, save_as=f\"./{ADV_SENS_ATTR}/adv_{load_num}_eval.txt\")\n",
    "\n",
    "sp, eo = get_fairness_metrics_adv(\n",
    "      adv_clf, X_train_imp_dropped, y_train_dropped, X_id_test_imp_dropped, y_id_test_dropped, X_ood_test_imp_dropped, y_ood_test_dropped,\n",
    "      sensitive_attr=ADV_SENS_ATTR, mute=False\n",
    "  )\n",
    "\n",
    "\n",
    "all_sp.append(sp)\n",
    "all_eo.append(eo)\n",
    "\n",
    "wd = calculate_wasserstein_distance(X_train, X_id_test, X_ood_test, mute=True)\n",
    "all_was_dist.append(wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hEz0kjv9oukv",
    "outputId": "e53f5ac5-d2f7-4053-f6d2-e8f7ff1f1f0d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-8b35e4531d17>:190: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataset = pd.concat([data_dict['2006'], data_dict['2008']], ignore_index=True)\n",
      "<ipython-input-2-8b35e4531d17>:191: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  X_train = pd.concat([dataset.drop(columns=[\"mortality_ten_years\"]), X_train])\n",
      "<ipython-input-2-8b35e4531d17>:48: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_train = X_train.drop(columns=all_na_cols).fillna(np.nan)\n",
      "<ipython-input-2-8b35e4531d17>:51: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_id_test = X_id_test.drop(columns=all_na_cols).fillna(np.nan)\n",
      "<ipython-input-2-8b35e4531d17>:54: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_ood_test = X_ood_test.drop(columns=all_na_cols).fillna(np.nan)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 - Accuracy: 0.6261\n",
      "Epoch 2/100 - Accuracy: 0.6353\n",
      "Epoch 3/100 - Accuracy: 0.6487\n",
      "Epoch 4/100 - Accuracy: 0.6612\n",
      "Epoch 5/100 - Accuracy: 0.6716\n",
      "Epoch 6/100 - Accuracy: 0.6805\n",
      "Epoch 7/100 - Accuracy: 0.6885\n",
      "Epoch 8/100 - Accuracy: 0.6948\n",
      "Epoch 9/100 - Accuracy: 0.7005\n",
      "Epoch 10/100 - Accuracy: 0.7053\n",
      "Epoch 11/100 - Accuracy: 0.7089\n",
      "Epoch 12/100 - Accuracy: 0.7113\n",
      "Epoch 13/100 - Accuracy: 0.7136\n",
      "Epoch 14/100 - Accuracy: 0.7156\n",
      "Epoch 15/100 - Accuracy: 0.7169\n",
      "Epoch 16/100 - Accuracy: 0.7185\n",
      "Epoch 17/100 - Accuracy: 0.7204\n",
      "Epoch 18/100 - Accuracy: 0.7226\n",
      "Epoch 19/100 - Accuracy: 0.7237\n",
      "Epoch 20/100 - Accuracy: 0.7254\n",
      "Epoch 21/100 - Accuracy: 0.7266\n",
      "Epoch 22/100 - Accuracy: 0.7287\n",
      "Epoch 23/100 - Accuracy: 0.7289\n",
      "Epoch 24/100 - Accuracy: 0.7300\n",
      "Epoch 25/100 - Accuracy: 0.7313\n",
      "Epoch 26/100 - Accuracy: 0.7330\n",
      "Epoch 27/100 - Accuracy: 0.7348\n",
      "Epoch 28/100 - Accuracy: 0.7353\n",
      "Epoch 29/100 - Accuracy: 0.7363\n",
      "Epoch 30/100 - Accuracy: 0.7375\n",
      "Epoch 31/100 - Accuracy: 0.7387\n",
      "Epoch 32/100 - Accuracy: 0.7395\n",
      "Epoch 33/100 - Accuracy: 0.7406\n",
      "Epoch 34/100 - Accuracy: 0.7417\n",
      "Epoch 35/100 - Accuracy: 0.7437\n",
      "Fairness metrics improved, continuing...\n",
      "Epoch 36/100 - Accuracy: 0.7450\n",
      "Epoch 37/100 - Accuracy: 0.7461\n",
      "Epoch 38/100 - Accuracy: 0.7467\n",
      "Epoch 39/100 - Accuracy: 0.7476\n",
      "Epoch 40/100 - Accuracy: 0.7483\n",
      "Fairness metrics improved, continuing...\n",
      "Epoch 41/100 - Accuracy: 0.7490\n",
      "Epoch 42/100 - Accuracy: 0.7500\n",
      "Epoch 43/100 - Accuracy: 0.7507\n",
      "Epoch 44/100 - Accuracy: 0.7515\n",
      "Epoch 45/100 - Accuracy: 0.7522\n",
      "No improvement in fairness metrics for 1 evaluations.\n",
      "Epoch 46/100 - Accuracy: 0.7530\n",
      "Epoch 47/100 - Accuracy: 0.7537\n",
      "Epoch 48/100 - Accuracy: 0.7543\n",
      "Epoch 49/100 - Accuracy: 0.7549\n",
      "Epoch 50/100 - Accuracy: 0.7558\n",
      "No improvement in fairness metrics for 2 evaluations.\n",
      "Early stopping: No significant improvement in fairness metrics.\n",
      "state_live_current:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:486: UserWarning: X has feature names, but AdversarialFairnessClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:486: UserWarning: X has feature names, but AdversarialFairnessClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical Parity Difference (Train): 0.1844262295081967\n",
      "Equalized Odds Difference (Train): 0.33333333333333337\n",
      "Statistical Parity Difference (ID Test): 0.3\n",
      "Equalized Odds Difference (ID Test): 0.5555555555555556\n",
      "Statistical Parity Difference (OOD Test): 0.75\n",
      "Equalized Odds Difference (OOD Test): 0.8\n"
     ]
    }
   ],
   "source": [
    "load_num = 6\n",
    "\n",
    "X_train, y_train, X_id_test, y_id_test, X_ood_test, y_ood_test = load_data_scenario_6(imputed=True)\n",
    "X_train_imp = X_train\n",
    "X_id_test_imp = X_id_test\n",
    "X_ood_test_imp = X_ood_test\n",
    "\n",
    "X_train_imp_dropped = X_train_imp[X_train_imp[ADV_SENS_ATTR].notna()]\n",
    "y_train_dropped = y_train[X_train_imp[ADV_SENS_ATTR].notna()]\n",
    "X_train_imp_drop_normed = imp_norm_drop_miss_pipe.fit_transform(X_train_imp_dropped)\n",
    "\n",
    "X_id_test_imp_dropped = X_id_test_imp[X_id_test_imp[ADV_SENS_ATTR].notna()]\n",
    "y_id_test_dropped = y_id_test[X_id_test_imp[ADV_SENS_ATTR].notna()]\n",
    "X_id_test_imp_drop_normed = imp_norm_drop_miss_pipe.transform(X_id_test_imp_dropped)\n",
    "\n",
    "X_ood_test_imp_dropped = X_ood_test_imp[X_ood_test_imp[ADV_SENS_ATTR].notna()]\n",
    "y_ood_test_dropped = y_ood_test[X_ood_test_imp[ADV_SENS_ATTR].notna()]\n",
    "X_ood_test_imp_drop_normed = imp_norm_drop_miss_pipe.transform(X_ood_test_imp_dropped)\n",
    "\n",
    "adv_clf, metrics_history = train_adv(X_train_imp_drop_normed, X_train_imp_dropped, y_train_dropped, X_id_test_imp_dropped, y_id_test_dropped, X_ood_test_imp_dropped, y_ood_test_dropped)\n",
    "\n",
    "with open(f'./{ADV_SENS_ATTR}/metrics_{load_num}_eval.pkl', 'wb') as file:\n",
    "    pickle.dump(metrics_history, file)\n",
    "\n",
    "evaluate(adv_clf, X_id_test, y_id_test, X_ood_test, y_ood_test, save_as=f\"./{ADV_SENS_ATTR}/adv_{load_num}_eval.txt\")\n",
    "\n",
    "sp, eo = get_fairness_metrics_adv(\n",
    "      adv_clf, X_train_imp_dropped, y_train_dropped, X_id_test_imp_dropped, y_id_test_dropped, X_ood_test_imp_dropped, y_ood_test_dropped,\n",
    "      sensitive_attr=ADV_SENS_ATTR, mute=False\n",
    "  )\n",
    "\n",
    "\n",
    "all_sp.append(sp)\n",
    "all_eo.append(eo)\n",
    "\n",
    "wd = calculate_wasserstein_distance(X_train, X_id_test, X_ood_test, mute=True)\n",
    "all_was_dist.append(wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "s36FvbUZowPy"
   },
   "outputs": [],
   "source": [
    "#save\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open(f'./{ADV_SENS_ATTR}/adv_was_dist.pkl', 'wb') as file:\n",
    "    pickle.dump(all_was_dist, file)\n",
    "\n",
    "with open(f'./{ADV_SENS_ATTR}/adv_sp.pkl', 'wb') as file:\n",
    "    pickle.dump(all_sp, file)\n",
    "\n",
    "with open(f'./{ADV_SENS_ATTR}/adv_eo.pkl', 'wb') as file:\n",
    "    pickle.dump(all_eo, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OSKhn_4isBQf",
    "outputId": "182f2e6f-29b4-4cc2-9ea5-f8d8569a26ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: content/state_live_current/ (stored 0%)\n",
      "  adding: content/state_live_current/metrics_3_eval.pkl (deflated 27%)\n",
      "  adding: content/state_live_current/adv_eo.pkl (deflated 42%)\n",
      "  adding: content/state_live_current/adv_5_eval.txt (deflated 72%)\n",
      "  adding: content/state_live_current/metrics_1_eval.pkl (deflated 29%)\n",
      "  adding: content/state_live_current/adv_2_eval.txt (deflated 71%)\n",
      "  adding: content/state_live_current/metrics_6_eval.pkl (deflated 27%)\n",
      "  adding: content/state_live_current/adv_3_eval.txt (deflated 71%)\n",
      "  adding: content/state_live_current/adv_6_eval.txt (deflated 71%)\n",
      "  adding: content/state_live_current/adv_sp.pkl (deflated 47%)\n",
      "  adding: content/state_live_current/metrics_2_eval.pkl (deflated 28%)\n",
      "  adding: content/state_live_current/adv_was_dist.pkl (deflated 52%)\n",
      "  adding: content/state_live_current/metrics_5_eval.pkl (deflated 29%)\n",
      "  adding: content/state_live_current/adv_1_eval.txt (deflated 71%)\n",
      "  adding: content/state_live_current/adv_4_eval.txt (deflated 71%)\n",
      "  adding: content/state_live_current/metrics_4_eval.pkl (deflated 26%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r /content/state_live_current.zip /content/state_live_current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SUiGPvBOwXef",
    "outputId": "baa45db6-3298-4a6d-a57e-f29cafe4f388"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: content/gender/ (stored 0%)\n",
      "  adding: content/gender/metrics_3_eval.pkl (deflated 26%)\n",
      "  adding: content/gender/adv_eo.pkl (deflated 17%)\n",
      "  adding: content/gender/adv_5_eval.txt (deflated 73%)\n",
      "  adding: content/gender/metrics_1_eval.pkl (deflated 27%)\n",
      "  adding: content/gender/adv_2_eval.txt (deflated 71%)\n",
      "  adding: content/gender/metrics_6_eval.pkl (deflated 27%)\n",
      "  adding: content/gender/adv_3_eval.txt (deflated 71%)\n",
      "  adding: content/gender/adv_6_eval.txt (deflated 71%)\n",
      "  adding: content/gender/adv_sp.pkl (deflated 41%)\n",
      "  adding: content/gender/metrics_2_eval.pkl (deflated 28%)\n",
      "  adding: content/gender/adv_was_dist.pkl (deflated 52%)\n",
      "  adding: content/gender/metrics_5_eval.pkl (deflated 26%)\n",
      "  adding: content/gender/adv_1_eval.txt (deflated 71%)\n",
      "  adding: content/gender/adv_4_eval.txt (deflated 70%)\n",
      "  adding: content/gender/metrics_4_eval.pkl (deflated 23%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r /content/gender.zip /content/gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PcLeXYluwbPf",
    "outputId": "048a8533-c35e-493d-c2e0-f81f3204c885"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: content/race/ (stored 0%)\n",
      "  adding: content/race/metrics_3_eval.pkl (deflated 31%)\n",
      "  adding: content/race/adv_eo.pkl (deflated 48%)\n",
      "  adding: content/race/adv_5_eval.txt (deflated 76%)\n",
      "  adding: content/race/metrics_1_eval.pkl (deflated 30%)\n",
      "  adding: content/race/adv_2_eval.txt (deflated 71%)\n",
      "  adding: content/race/metrics_6_eval.pkl (deflated 31%)\n",
      "  adding: content/race/adv_3_eval.txt (deflated 70%)\n",
      "  adding: content/race/adv_6_eval.txt (deflated 71%)\n",
      "  adding: content/race/adv_sp.pkl (deflated 46%)\n",
      "  adding: content/race/metrics_2_eval.pkl (deflated 30%)\n",
      "  adding: content/race/adv_was_dist.pkl (deflated 58%)\n",
      "  adding: content/race/metrics_5_eval.pkl (deflated 30%)\n",
      "  adding: content/race/adv_1_eval.txt (deflated 71%)\n",
      "  adding: content/race/adv_4_eval.txt (deflated 70%)\n",
      "  adding: content/race/metrics_4_eval.pkl (deflated 22%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r /content/race.zip /content/race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "48HElrNnweIU"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
