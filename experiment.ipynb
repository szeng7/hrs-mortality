{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad5482ea-264c-4c44-9f78-448b847e4aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "from fairlearn.metrics import *\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67d37466-6168-427f-945f-56d21c655acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_clean_X_y(dataset, label_to_use = \"mortality_five_years\"):\n",
    "    y = dataset[label_to_use]\n",
    "   #drop all data that is completely empty\n",
    "    # dataset = dataset.loc[~dataset.index.duplicated(keep='first')]\n",
    "    dataset = dataset.drop(columns=[\"rmonth_survey\",\"ryear_survey\",\"HHID\",\"PN\",\"heart_condition_compared_to_prev\", #maybe later just drop 1st heart featuer\n",
    "                          \"mortality_five_years\",\"mortality_ten_years\",\"Key\",\"year_death\"]) # this has duplicate\n",
    "    dataset = dataset.dropna(axis=1, thresh=len(dataset)*0.75)\n",
    "    return dataset, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8bff0c11-00a8-44e2-b71a-ab4a4f3306a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HHID</th>\n",
       "      <th>PN</th>\n",
       "      <th>rmonth_survey</th>\n",
       "      <th>ryear_survey</th>\n",
       "      <th>age</th>\n",
       "      <th>live_nursing_facility</th>\n",
       "      <th>divorce_widow_status</th>\n",
       "      <th>health_status</th>\n",
       "      <th>health_status_compared_to_prev</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>cancer</th>\n",
       "      <th>lung_disease</th>\n",
       "      <th>heart_condition</th>\n",
       "      <th>stroke</th>\n",
       "      <th>psychiatric_emotional_problem</th>\n",
       "      <th>arthritis</th>\n",
       "      <th>pain</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>shortness_breath</th>\n",
       "      <th>fatigue</th>\n",
       "      <th>cough</th>\n",
       "      <th>depressed_x</th>\n",
       "      <th>memory</th>\n",
       "      <th>depressed_y</th>\n",
       "      <th>dependents</th>\n",
       "      <th>type_house</th>\n",
       "      <th>own_or_rent</th>\n",
       "      <th>cooperation</th>\n",
       "      <th>tiredness</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>state_live</th>\n",
       "      <th>gender</th>\n",
       "      <th>year_born_y</th>\n",
       "      <th>leave_inheritance</th>\n",
       "      <th>wave</th>\n",
       "      <th>Key</th>\n",
       "      <th>year_death</th>\n",
       "      <th>mortality_ten_years</th>\n",
       "      <th>mortality_five_years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>010001</td>\n",
       "      <td>010</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1939.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>010001-010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     HHID   PN  rmonth_survey  ryear_survey   age  live_nursing_facility divorce_widow_status  health_status health_status_compared_to_prev  high_blood_pressure diabetes cancer lung_disease heart_condition stroke psychiatric_emotional_problem arthritis pain alcohol shortness_breath fatigue cough depressed_x memory depressed_y dependents type_house own_or_rent cooperation tiredness employment_status state_live  gender  year_born_y leave_inheritance  wave         Key  year_death  mortality_ten_years  mortality_five_years\n",
       "0  010001  010            5.0        2016.0  76.0                    5.0                  5.0            2.0                            2.0                  5.0      5.0    5.0          5.0             5.0    5.0                           5.0       5.0  5.0     5.0              5.0     5.0   5.0         5.0    3.0         5.0        5.0        4.0         2.0         3.0       1.0               5.0        2.0     1.0       1939.0               0.0  13.0  010001-010           0                    0                     0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_pickle(\"hrs_data_2016.pkl\").iloc[0:1].dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b39b09d2-3e86-458b-9f76-2fa4a9fddb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data_2002_X,small_data_2002_y = make_clean_X_y(pd.read_pickle(\"hrs_data_2002.pkl\").iloc[0:100])\n",
    "small_data_2004_X,small_data_2004_y = make_clean_X_y(pd.read_pickle(\"hrs_data_2004.pkl\").iloc[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82ce6297-3372-4d70-b5d4-c70a076bbe74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 38 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   age                             100 non-null    object \n",
      " 1   live_nursing_facility           100 non-null    float64\n",
      " 2   race                            100 non-null    object \n",
      " 3   divorce_widow_status            96 non-null     object \n",
      " 4   marital_status                  100 non-null    object \n",
      " 5   health_status                   100 non-null    float64\n",
      " 6   health_status_compared_to_prev  100 non-null    object \n",
      " 7   high_blood_pressure             100 non-null    float64\n",
      " 8   diabetes                        100 non-null    float64\n",
      " 9   cancer                          100 non-null    float64\n",
      " 10  lung_disease                    100 non-null    float64\n",
      " 11  heart_condition                 100 non-null    float64\n",
      " 12  stroke                          100 non-null    float64\n",
      " 13  psychiatric_emotional_problem   100 non-null    float64\n",
      " 14  arthritis                       100 non-null    float64\n",
      " 15  pain                            100 non-null    float64\n",
      " 16  exercise                        100 non-null    float64\n",
      " 17  still_smoke                     100 non-null    object \n",
      " 18  alcohol                         100 non-null    float64\n",
      " 19  memory_x                        100 non-null    object \n",
      " 20  depressed_y                     100 non-null    object \n",
      " 21  children_nearby                 98 non-null     object \n",
      " 22  dependents                      99 non-null     object \n",
      " 23  type_house                      100 non-null    object \n",
      " 24  own_or_rent                     100 non-null    object \n",
      " 25  vocab_level                     100 non-null    object \n",
      " 26  friendliness                    100 non-null    object \n",
      " 27  attentiveness                   100 non-null    object \n",
      " 28  cooperation                     100 non-null    object \n",
      " 29  tiredness                       100 non-null    object \n",
      " 30  memory_y                        100 non-null    object \n",
      " 31  hearing                         100 non-null    object \n",
      " 32  employment_status               100 non-null    object \n",
      " 33  state_live                      100 non-null    object \n",
      " 34  gender                          100 non-null    float64\n",
      " 35  year_born_y                     100 non-null    float64\n",
      " 36  financial_expectation           100 non-null    object \n",
      " 37  wave                            100 non-null    float64\n",
      "dtypes: float64(16), object(22)\n",
      "memory usage: 29.8+ KB\n"
     ]
    }
   ],
   "source": [
    "small_data_2002_X.info(verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1600dfdc-a0ba-4a1c-9f2c-61aaf3a6f965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<NA>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_data_2002_X.iloc[4][\"divorce_widow_status\"]==pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e354c657-74ff-46d1-80d8-6b330ecaefe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset_X = pd.concat([small_data_2002_X,small_data_2004_X], ignore_index=True)\n",
    "full_dataset_y = pd.concat([small_data_2002_y,small_data_2004_y], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575dd7ac-0ee7-48ea-bdef-63e181a5065f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "008ac882-421f-4e33-b919-09ea5f43e670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_subset(data_subset_X, data_subset_y, data_full_X,data_full_y, model):\n",
    "    # (regular) full to full eg. 2002 + all other years tested on 2002 + all other years\n",
    "    X_train, X_test, y_train, y_test, race_train,race_test = train_test_split(data_full_X, data_full_y,data_full_X[\"race\"], random_state=5)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # choose more from here: https://fairlearn.org/main/api_reference/generated/fairlearn.metrics.equal_opportunity_difference.html\n",
    "    metrics_needed = {\n",
    "        'demo_parity_diff' : demographic_parity_difference,\n",
    "        'demo_parity_ratio' : demographic_parity_ratio,\n",
    "        'eq_parity_diff' : equalized_odds_difference,\n",
    "        'eq_parity_ratio' : equalized_odds_ratio,\n",
    "        'count' : count\n",
    "    }\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    metric_frame = MetricFrame(\n",
    "        metrics=metrics_needed, y_true=y_test, y_pred=y_pred, sensitive_features=race_test\n",
    "    )\n",
    "    metric_frame.by_group.plot.bar(\n",
    "        subplots=True,\n",
    "        layout=[3, 3],\n",
    "        legend=False,\n",
    "        figsize=[12, 8],\n",
    "        title=\"Show all metrics\",\n",
    "    )\n",
    "\n",
    "    # just duplicate above code for other sections\n",
    "\n",
    "    # # subset to subset ex. 2002 only tested on 2002\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(data_full_X, data_full_y, random_state=5)\n",
    "    # model.fit(X_train, y_train)\n",
    "\n",
    "    # # subset to full ex. 2002 tested on 2002 + all other years\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(data_full_X, data_full_y, random_state=5)\n",
    "    # model.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d11b0f-a73e-4914-8750-a06a6b520903",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Might need to use the column transformer instead if there's still trouble with imputation\n",
    "ct = make_column_transformer(\n",
    "    (\n",
    "        Pipeline(\n",
    "            [\n",
    "                (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "                (\"normalizer\", StandardScaler()),\n",
    "            ]\n",
    "        ),\n",
    "        make_column_selector(dtype_include=number),\n",
    "    ),\n",
    "    (\n",
    "        Pipeline(\n",
    "            [\n",
    "                (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                (\"encoder\", OneHotEncoder(drop=\"if_binary\", sparse_output=False)),\n",
    "            ]\n",
    "        ),\n",
    "        make_column_selector(dtype_include=\"category\"),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "665c7fb4-af04-40df-b68e-2c6d5565a921",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'missing_value'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 11\u001b[0m\n\u001b[0;32m      4\u001b[0m classifier \u001b[38;5;241m=\u001b[39m DecisionTreeClassifier(min_samples_leaf\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m      5\u001b[0m pipe \u001b[38;5;241m=\u001b[39m Pipeline(steps\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m      6\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimputer\u001b[39m\u001b[38;5;124m\"\u001b[39m, SimpleImputer(strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m)),\n\u001b[0;32m      7\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnormalizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, StandardScaler()),\n\u001b[0;32m      8\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclf\u001b[39m\u001b[38;5;124m\"\u001b[39m, classifier),\n\u001b[0;32m      9\u001b[0m     ])\n\u001b[1;32m---> 11\u001b[0m \u001b[43mtrain_with_subset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_dataset_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mfull_dataset_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpipe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Expotentiated Gradient\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 4\u001b[0m, in \u001b[0;36mtrain_with_subset\u001b[1;34m(data_subset_X, data_subset_y, data_full_X, data_full_y, model)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_with_subset\u001b[39m(data_subset_X, data_subset_y, data_full_X,data_full_y, model):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# (regular) full to full eg. 2002 + all other years tested on 2002 + all other years0\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     X_train, X_test, y_train, y_test, race_train,race_test \u001b[38;5;241m=\u001b[39m train_test_split(data_full_X, data_full_y,data_full_X[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrace\u001b[39m\u001b[38;5;124m\"\u001b[39m], random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     my_metrics \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtpr\u001b[39m\u001b[38;5;124m'\u001b[39m : recall_score,\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfpr\u001b[39m\u001b[38;5;124m'\u001b[39m : false_positive_rate,\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msel\u001b[39m\u001b[38;5;124m'\u001b[39m : selection_rate,\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m : count\n\u001b[0;32m     10\u001b[0m     }\n\u001b[0;32m     11\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m (classifier\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)[:,\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m)\n",
      "File \u001b[1;32m~\\Development\\School\\Fall2024\\FairML\\project\\venv\\lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Development\\School\\Fall2024\\FairML\\project\\venv\\lib\\site-packages\\sklearn\\pipeline.py:469\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model.\u001b[39;00m\n\u001b[0;32m    427\u001b[0m \n\u001b[0;32m    428\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and sequentially transform the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;124;03m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    468\u001b[0m routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_method_params(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, props\u001b[38;5;241m=\u001b[39mparams)\n\u001b[1;32m--> 469\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\Development\\School\\Fall2024\\FairML\\project\\venv\\lib\\site-packages\\sklearn\\pipeline.py:406\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, routed_params)\u001b[0m\n\u001b[0;32m    404\u001b[0m     cloned_transformer \u001b[38;5;241m=\u001b[39m clone(transformer)\n\u001b[0;32m    405\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[1;32m--> 406\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[1;32m~\\Development\\School\\Fall2024\\FairML\\project\\venv\\lib\\site-packages\\joblib\\memory.py:312\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Development\\School\\Fall2024\\FairML\\project\\venv\\lib\\site-packages\\sklearn\\pipeline.py:1310\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, params)\u001b[0m\n\u001b[0;32m   1308\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m   1309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1310\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit_transform(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))\n\u001b[0;32m   1311\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1312\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[0;32m   1313\u001b[0m             X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[0;32m   1314\u001b[0m         )\n",
      "File \u001b[1;32m~\\Development\\School\\Fall2024\\FairML\\project\\venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    322\u001b[0m         )\n",
      "File \u001b[1;32m~\\Development\\School\\Fall2024\\FairML\\project\\venv\\lib\\site-packages\\sklearn\\base.py:1101\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m-> 1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\Development\\School\\Fall2024\\FairML\\project\\venv\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:878\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 878\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Development\\School\\Fall2024\\FairML\\project\\venv\\lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Development\\School\\Fall2024\\FairML\\project\\venv\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:914\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    882\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[0;32m    883\u001b[0m \n\u001b[0;32m    884\u001b[0m \u001b[38;5;124;03mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    911\u001b[0m \u001b[38;5;124;03m    Fitted scaler.\u001b[39;00m\n\u001b[0;32m    912\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    913\u001b[0m first_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 914\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    921\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    923\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Development\\School\\Fall2024\\FairML\\project\\venv\\lib\\site-packages\\sklearn\\base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32m~\\Development\\School\\Fall2024\\FairML\\project\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1012\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1010\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1012\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m   1014\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1015\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m   1016\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\Development\\School\\Fall2024\\FairML\\project\\venv\\lib\\site-packages\\sklearn\\utils\\_array_api.py:745\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[0;32m    743\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 745\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    749\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'missing_value'"
     ]
    }
   ],
   "source": [
    "from fairlearn.reductions import ErrorRate, EqualizedOdds, ExponentiatedGradient\n",
    "\n",
    "# Control, no fairness (Decision Tree), should be replaceable with RandomForestClassifier()\n",
    "classifier = DecisionTreeClassifier(min_samples_leaf=10, max_depth=4)\n",
    "pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\")),\n",
    "    (\"normalizer\", StandardScaler()),\n",
    "    (\"clf\", classifier),\n",
    "    ])\n",
    "\n",
    "train_with_subset(None, None, full_dataset_X,  full_dataset_X, pipe)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1724b5f4-eca2-4322-b05e-851df97e844d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expotentiated Gradient constraint, should be replaceable with RandomForestClassifier()\n",
    "\n",
    "objective = ErrorRate(costs={'fp': 0.1, 'fn': 0.9})\n",
    "constraint = EqualizedOdds(difference_bound=0.01) # can be changed to other constraints instead \n",
    "# see fairlearn.reduction around here: https://fairlearn.org/main/api_reference/generated/fairlearn.reductions.DemographicParity.html\n",
    "classifier = DecisionTreeClassifier(min_samples_leaf=10, max_depth=4)\n",
    "mitigator = ExponentiatedGradient(classifier, constraint, objective=objective)\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\")),\n",
    "    (\"normalizer\", StandardScaler()),\n",
    "    (\"clf\", mitigator),\n",
    "    ])\n",
    "\n",
    "train_with_subset(None, None, full_dataset_X,  full_dataset_X, pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f1ca8c-a3f3-4ab7-a241-e20189bed3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adversarial learning, should be replaceable with RandomForestClassifier()\n",
    "from fairlearn.adversarial import AdversarialFairnessClassifier\n",
    "\n",
    "mitigator = AdversarialFairnessClassifier(\n",
    "    backend=\"torch\",\n",
    "    predictor_model=[50, \"leaky_relu\"], # this is number of nodes and then activation function, see here: https://fairlearn.org/main/api_reference/generated/fairlearn.adversarial.AdversarialFairnessClassifier.html#:~:text=a%20BackendEngine%20class.-,predictor_model,-list%2C%20torch.nn\n",
    "    adversary_model=[3, \"leaky_relu\"],\n",
    "    batch_size=2**8,\n",
    "    progress_updates=0.5,\n",
    "    random_state=5,\n",
    "    #contraints = \"demographic_parity\" # we can chagne this to equalized_odds as per https://fairlearn.org/main/api_reference/generated/fairlearn.adversarial.AdversarialFairnessClassifier.html#:~:text=constraintsstr%2C%20default,demographic_parity%E2%80%99%20or%20%E2%80%98equalized_odds%E2%80%99.\n",
    ")\n",
    "\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\")),\n",
    "    (\"normalizer\", StandardScaler()),\n",
    "    (\"clf\", mitigator),\n",
    "    ])\n",
    "\n",
    "train_with_subset(None, None, full_dataset_X,  full_dataset_X, pipe)\n",
    "\n",
    "# slightly more advanced usage of adversarial training here: https://fairlearn.org/main/auto_examples/plot_adversarial_fine_tuning.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30f23f0-1c07-4718-b5fb-f8695cf40021",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
